/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.phoenix.pherf.workload.mt.tenantoperation;

import org.apache.phoenix.thirdparty.com.google.common.base.Charsets;
import org.apache.phoenix.thirdparty.com.google.common.base.Function;
import org.apache.phoenix.thirdparty.com.google.common.base.Supplier;
import org.apache.phoenix.thirdparty.com.google.common.collect.Lists;
import org.apache.phoenix.thirdparty.com.google.common.collect.Maps;
import org.apache.phoenix.thirdparty.com.google.common.hash.BloomFilter;
import org.apache.phoenix.thirdparty.com.google.common.hash.Funnel;
import org.apache.phoenix.thirdparty.com.google.common.hash.PrimitiveSink;
import org.apache.phoenix.pherf.configuration.DataModel;
import org.apache.phoenix.pherf.configuration.Ddl;
import org.apache.phoenix.pherf.configuration.IdleTime;
import org.apache.phoenix.pherf.configuration.LoadProfile;
import org.apache.phoenix.pherf.configuration.Query;
import org.apache.phoenix.pherf.configuration.QuerySet;
import org.apache.phoenix.pherf.configuration.Scenario;
import org.apache.phoenix.pherf.configuration.TenantGroup;
import org.apache.phoenix.pherf.configuration.Upsert;
import org.apache.phoenix.pherf.configuration.UserDefined;
import org.apache.phoenix.pherf.configuration.XMLConfigParser;
import org.apache.phoenix.pherf.rules.RulesApplier;
import org.apache.phoenix.pherf.util.PhoenixUtil;
import org.apache.phoenix.pherf.workload.mt.EventGenerator;
import org.apache.phoenix.pherf.workload.mt.IdleTimeOperation;
import org.apache.phoenix.pherf.workload.mt.Operation;
import org.apache.phoenix.pherf.workload.mt.OperationStats;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.List;
import java.util.Map;

/**
 * Factory class for operation suppliers.
 * The class is responsible for creating new instances of suppliers {@link Supplier}
 * for operations {@link Operation}
 *
 * Operations that need to be executed for a given {@link Scenario} and {@link DataModel}
 * are generated by {@link EventGenerator}
 *
 * These operation events are then published on to the {@link com.lmax.disruptor.RingBuffer}
 * by the {@link TenantOperationWorkload} workload generator and
 * handled by the {@link com.lmax.disruptor.WorkHandler} for eg {@link TenantOperationWorkHandler}
 */
public class TenantOperationFactory {

    private static class TenantView {
        private final String tenantId;
        private final String viewName;

        public TenantView(String tenantId, String viewName) {
            this.tenantId = tenantId;
            this.viewName = viewName;
        }

        public String getTenantId() {
            return tenantId;
        }

        public String getViewName() {
            return viewName;
        }
    }
    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationFactory.class);
    private final PhoenixUtil phoenixUtil;
    private final DataModel model;
    private final Scenario scenario;
    private final XMLConfigParser parser;

    private final RulesApplier rulesApplier;
    private final LoadProfile loadProfile;
    private final List<Operation> operationList = Lists.newArrayList();
    private final Map<Operation.OperationType, Supplier<Function<TenantOperationInfo, OperationStats>>> operationSuppliers =
            Maps.newEnumMap(Operation.OperationType.class);

    private final BloomFilter<TenantView> tenantsLoaded;

    public TenantOperationFactory(PhoenixUtil phoenixUtil, DataModel model, Scenario scenario) {
        this.phoenixUtil = phoenixUtil;
        this.model = model;
        this.scenario = scenario;
        this.parser = null;
        this.rulesApplier = new RulesApplier(model);
        this.loadProfile = this.scenario.getLoadProfile();
        Funnel<TenantView> tenantViewFunnel = new Funnel<TenantView>() {
            @Override
            public void funnel(TenantView tenantView, PrimitiveSink into) {
                into.putString(tenantView.getTenantId(), Charsets.UTF_8)
                        .putString(tenantView.getViewName(), Charsets.UTF_8);
            }
        };

        int numTenants = 0;
        for (TenantGroup tg : loadProfile.getTenantDistribution()) {
            numTenants += tg.getNumTenants();
        }

        // This holds the info whether the tenant view was created (initialized) or not.
        tenantsLoaded = BloomFilter.create(tenantViewFunnel, numTenants, 0.01);

        if (scenario.getPreScenarioDdls() != null && scenario.getPreScenarioDdls().size() > 0) {
            operationSuppliers.put(Operation.OperationType.PRE_RUN,
                    new PreScenarioOperationSupplier(phoenixUtil, model, scenario));
        }

        // Read the scenario definition and load the various operations.
        // Case : Operation.OperationType.UPSERT
        for (final Upsert upsert : scenario.getUpserts()) {
            Operation upsertOp = new org.apache.phoenix.pherf.workload.mt.UpsertOperation() {
                @Override public Upsert getUpsert() {
                    return upsert;
                }

                @Override public String getId() {
                    return upsert.getId();
                }

                @Override public OperationType getType() {
                    return OperationType.UPSERT;
                }
            };
            operationList.add(upsertOp);
        }
        if (scenario.getUpserts() != null && scenario.getUpserts().size() > 0) {
            operationSuppliers.put(Operation.OperationType.UPSERT,
                    new UpsertOperationSupplier(phoenixUtil, model, scenario));
        }

        // Case : Operation.OperationType.SELECT
        for (final QuerySet querySet : scenario.getQuerySet()) {
            for (final Query query : querySet.getQuery()) {
                Operation queryOp = new org.apache.phoenix.pherf.workload.mt.QueryOperation() {
                    @Override public Query getQuery() {
                        return query;
                    }

                    @Override public String getId() {
                        return query.getId();
                    }

                    @Override public OperationType getType() {
                        return OperationType.SELECT;
                    }
                };
                operationList.add(queryOp);
            }
        }
        if (scenario.getQuerySet() != null && scenario.getQuerySet().size() > 0) {
            operationSuppliers.put(Operation.OperationType.SELECT,
                    new QueryOperationSupplier(phoenixUtil, model, scenario));
        }

        // Case : Operation.OperationType.IDLE_TIME
        for (final IdleTime idleTime : scenario.getIdleTimes()) {
            Operation idleTimeOperation = new IdleTimeOperation() {
                @Override public IdleTime getIdleTime() {
                    return idleTime;
                }
                @Override public String getId() {
                    return idleTime.getId();
                }

                @Override public OperationType getType() {
                    return OperationType.IDLE_TIME;
                }
            };
            operationList.add(idleTimeOperation);
        }
        if (scenario.getIdleTimes() != null && scenario.getIdleTimes().size() > 0) {
            operationSuppliers.put(Operation.OperationType.IDLE_TIME,
                    new IdleTimeOperationSupplier(phoenixUtil, model, scenario));
        }

        // Case : Operation.OperationType.USER_DEFINED
        for (final UserDefined udf : scenario.getUdfs()) {
            Operation udfOperation = new org.apache.phoenix.pherf.workload.mt.UserDefinedOperation() {
                @Override public UserDefined getUserFunction() {
                    return udf;
                }

                @Override public String getId() {
                    return udf.getId();
                }

                @Override public OperationType getType() {
                    return OperationType.USER_DEFINED;
                }
            };
            operationList.add(udfOperation);
        }
        if (scenario.getUdfs() != null && scenario.getUdfs().size() > 0) {
            operationSuppliers.put(Operation.OperationType.USER_DEFINED,
                    new UserDefinedOperationSupplier(phoenixUtil, model, scenario));
        }
    }

    public PhoenixUtil getPhoenixUtil() {
        return phoenixUtil;
    }

    public DataModel getModel() {
        return model;
    }

    public Scenario getScenario() {
        return scenario;
    }

    public List<Operation> getOperationsForScenario() {
        return operationList;
    }

    public Supplier<Function<TenantOperationInfo, OperationStats>> getOperationSupplier(
            final TenantOperationInfo input) {
        TenantView tenantView = new TenantView(input.getTenantId(), scenario.getTableName());

        // Check if pre run ddls are needed.
        if (!tenantsLoaded.mightContain(tenantView)) {

            Supplier<Function<TenantOperationInfo, OperationStats>> preRunOpSupplier =
                    operationSuppliers.get(Operation.OperationType.PRE_RUN);
            // Check if the scenario has a PRE_RUN operation.
            if (preRunOpSupplier != null) {
                // Initialize the tenant using the pre scenario ddls.
                final org.apache.phoenix.pherf.workload.mt.PreScenarioOperation
                        operation = new org.apache.phoenix.pherf.workload.mt.PreScenarioOperation() {
                    @Override public List<Ddl> getPreScenarioDdls() {
                        List<Ddl> ddls = scenario.getPreScenarioDdls();
                        return ddls == null ? Lists.<Ddl>newArrayList() : ddls;
                    }

                    @Override public String getId() {
                        return OperationType.PRE_RUN.name();
                    }

                    @Override public OperationType getType() {
                        return OperationType.PRE_RUN;
                    }
                };
                // Initialize with the pre run operation.
                TenantOperationInfo preRunSample = new TenantOperationInfo(
                        input.getModelName(),
                        input.getScenarioName(),
                        input.getTableName(),
                        input.getTenantGroupId(),
                        Operation.OperationType.PRE_RUN.name(),
                        input.getTenantId(), operation);

                try {
                    // Run the initialization operation.
                    OperationStats stats = preRunOpSupplier.get().apply(preRunSample);
                    LOGGER.info(phoenixUtil.getGSON().toJson(stats));
                } catch (Exception e) {
                    LOGGER.error(String.format("Failed to initialize tenant. [%s, %s] ",
                            tenantView.tenantId,
                            tenantView.viewName), e);
                }
            }

            tenantsLoaded.put(tenantView);
        }

        Supplier<Function<TenantOperationInfo, OperationStats>> opSupplier =
                operationSuppliers.get(input.getOperation().getType());
        if (opSupplier == null) {
            throw new IllegalArgumentException("Unknown operation type");
        }
        return opSupplier;
    }

}
